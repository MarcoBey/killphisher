
<!doctype html>

<html>
<head>
  <meta charset="utf-8">
  <title>jsfeat - ORB features</title>
  <link rel="stylesheet" href="assets/demo.css">

  <script src="./build/jsfeat-min.js"></script>
  <script src="./orb_utils.js"></script>

  <style>
  .demo-container {
    background-color: black;
  }
  #image1, #image2 {
    position: absolute;
    left: -1000px;
    top: -1000px;
  }
  </style>
</head>
<body>
  <div class="demo-title1">
  </div>

  <div class="demo-frame1">
    <div class="demo-container1">
      <img id="image1" src="fb-logo_lnx.png" />
      <img id="image2" src="fb-site.png"/>
      <canvas id="canvas" width="786" height="295"></canvas>
    </div>
  </div>
  <script>
  window.onload = function() {

    var image1 = document.getElementById('image1');
    var image2 = document.getElementById('image2');
    var canvas = document.getElementById('canvas');
    //var canvas = document.createElement('canvas');
    canvas.width = image1.width + image2.width + 200;
    canvas.height = image1.height + image2.height + 200;
    var ctx = canvas.getContext('2d');
   
	ctx.drawImage(image1, 0, 0, image1.width, image1.height);
    ctx.drawImage(image2, 200, 0, image2.width, image2.height);
    var imageData1 = ctx.getImageData(0, 0, image1.width, image1.height);
    var imageData2 = ctx.getImageData(200, 0, image2.width, image2.height);
    
    //Params to play around with
	var blur_size = 5;
    var match_threshold = 48;//increasing this increases the number of points found. hence increases noise.
    var num_train_levels = 4; // no. of stages in the pyramid
	jsfeat.yape06.laplacian_threshold = 30; //not really sure what influence this has
	jsfeat.yape06.min_eigen_value_threshold = 25;// ditto

    //data strs for the screenshot
    var scrShot_u8, scrShot_u8_smooth, scrShot_corners, scrShot_descriptors, num_scrShot_corners;
    var  matches, homo3x3, match_mask;
    
    //data strs for patten/logo
    var pattern_corners, pattern_descriptors;
    var max_pattern_size = 512;
    var max_per_level = 300;
    var sc_inc = Math.sqrt(2.0); // magic number ;)

	scrShot_u8 = new jsfeat.matrix_t(image2.width, image2.height, jsfeat.U8_t | jsfeat.C1_t);
	scrShot_u8_smooth = new jsfeat.matrix_t(image2.width, image2.height, jsfeat.U8_t | jsfeat.C1_t);
	
    // we wll limit to 500 strongest points
	pattern_descriptors = [];
	scrShot_descriptors= new jsfeat.matrix_t(32, 500, jsfeat.U8_t | jsfeat.C1_t);
	scrShot_corners = [];
	pattern_corners = [];
	matches = [];
	var i = image2.width * image2.height;
	while(--i >= 0) {
		scrShot_corners[i] = new jsfeat.keypoint_t(0,0,0,0,-1);
		matches[i] = new match_t();
	}
    
	// estimate homography transform between matched points
	function find_transform(matches, count) {
		// motion kernel
		var mm_kernel = new jsfeat.motion_model.homography2d();
		// ransac params
		var num_model_points = 4;
		var reproj_threshold = 3;
		var ransac_param = new jsfeat.ransac_params_t(num_model_points,
													  reproj_threshold, 0.5, 0.99);

		var pattern_xy = [];
		var screen_xy = [];

		// construct correspondences
		for(var i = 0; i < count; ++i) {
			var m = matches[i];
			var s_kp = scrShot_corners[m.screen_idx];
			var p_kp = pattern_corners[m.pattern_lev][m.pattern_idx];
			pattern_xy[i] = {"x":p_kp.x, "y":p_kp.y};
			screen_xy[i] =  {"x":s_kp.x, "y":s_kp.y};
		}

		// estimate motion
		var ok = false;
		ok = jsfeat.motion_estimator.ransac(ransac_param, mm_kernel,
											pattern_xy, screen_xy, count, homo3x3, match_mask, 1000);

		// extract good matches and re-estimate
		var good_cnt = 0;
		if(ok) {
			for(var i=0; i < count; ++i) {
				if(match_mask.data[i]) {
					pattern_xy[good_cnt].x = pattern_xy[i].x;
					pattern_xy[good_cnt].y = pattern_xy[i].y;
					screen_xy[good_cnt].x = screen_xy[i].x;
					screen_xy[good_cnt].y = screen_xy[i].y;
					good_cnt++;
				}
			}
			// run kernel directly with inliers only
			mm_kernel.run(pattern_xy, screen_xy, homo3x3, good_cnt);
		} else {
			jsfeat.matmath.identity_3x3(homo3x3, 1.0);
		}

		return good_cnt;
	}

	// naive brute-force matching.
	// each on screen point is compared to all pattern points
	// to find the closest match
	function match_pattern() {
		var q_cnt = scrShot_descriptors.rows;
		var query_du8 = scrShot_descriptors.data;
		var query_u32 = scrShot_descriptors.buffer.i32; // cast to integer buffer
		var qd_off = 0;
		var qidx=0,lev=0,pidx=0,k=0;
		var num_matches = 0;

		for(qidx = 0; qidx < q_cnt; ++qidx) {
			var best_dist = 256;
			var best_dist2 = 256;
			var best_idx = -1;
			var best_lev = -1;

			for(lev = 0; lev < num_train_levels; ++lev) {
				var lev_descr = pattern_descriptors[lev];
				var ld_cnt = lev_descr.rows;
				var ld_i32 = lev_descr.buffer.i32; // cast to integer buffer
				var ld_off = 0;

				for(pidx = 0; pidx < ld_cnt; ++pidx) {

					var curr_d = 0;
					// our descriptor is 32 bytes so we have 8 Integers
					for(k=0; k < 8; ++k) {
						curr_d += popcnt32( query_u32[qd_off+k]^ld_i32[ld_off+k] );
					}

					if(curr_d < best_dist) {
						best_dist2 = best_dist;
						best_dist = curr_d;
						best_lev = lev;
						best_idx = pidx;
					} else if(curr_d < best_dist2) {
						best_dist2 = curr_d;
					}

					ld_off += 8; // next descriptor
				}
			}

			// filter out by some threshold
			if(best_dist < match_threshold) {
				matches[num_matches].screen_idx = qidx;
				matches[num_matches].pattern_lev = best_lev;
				matches[num_matches].pattern_idx = best_idx;
				num_matches++;
			}

			qd_off += 8; // next query descriptor
		}

		return num_matches;
	}
	
	function render_matches(ctx, matches, count) {

		for(var i = 0; i < count; ++i) {
			var m = matches[i];
			var s_kp = scrShot_corners[m.screen_idx];
			var p_kp = pattern_corners[m.pattern_lev][m.pattern_idx];
			if(match_mask.data[i]) {
				ctx.strokeStyle = "rgb(0,255,0)";
			} else {
				ctx.strokeStyle = "rgb(255,0,0)";
			}
			ctx.beginPath();
			ctx.moveTo(s_kp.x + 200,s_kp.y);
			ctx.lineTo(p_kp.x, p_kp.y);
			ctx.lineWidth=1;
			ctx.stroke();
		}
	}
	// transform matrix
	homo3x3 = new jsfeat.matrix_t(3,3,jsfeat.F32C1_t);
	match_mask = new jsfeat.matrix_t(500,1,jsfeat.U8C1_t);
    
    
    var lev0_img = new jsfeat.matrix_t(image1.width, image1.height, jsfeat.U8_t | jsfeat.C1_t);
    var lev_img = new jsfeat.matrix_t(image1.width, image1.height, jsfeat.U8_t | jsfeat.C1_t);
    var lev_corners, lev_descr;
    var corners_num=0;
    var sc = 1;
    var sc0 = Math.min(max_pattern_size/lev0_img.cols, max_pattern_size/lev0_img.rows);
	jsfeat.imgproc.grayscale(imageData1.data, image1.width, image1.height, lev0_img);
    for(lev=0; lev < num_train_levels; ++lev) {
        pattern_corners[lev] = [];
        lev_corners = pattern_corners[lev];

        // preallocate corners array
        i = (image1.width * image1.height) >> lev;
        while(--i >= 0) {
            lev_corners[i] = new jsfeat.keypoint_t(0,0,0,0,-1);
        }

        pattern_descriptors[lev] = new jsfeat.matrix_t(32, max_per_level, jsfeat.U8_t | jsfeat.C1_t);
    }

    // do the first level
    lev_corners = pattern_corners[0];
    lev_descr = pattern_descriptors[0];

    jsfeat.imgproc.gaussian_blur(lev0_img, lev_img, blur_size); // this is more robust
    corners_num = detect_keypoints(lev_img, lev_corners, max_per_level);
    console.log("corners_num : " + corners_num);
    jsfeat.orb.describe(lev_img, lev_corners, corners_num, lev_descr);

    console.log("train " + lev_img.cols + "x" + lev_img.rows + " points: " + corners_num);

    sc /= sc_inc;

    // lets do multiple scale levels
    // we can use Canvas context draw method for faster resize
    // but its nice to demonstrate that you can do everything with jsfeat
    for(lev = 1; lev < num_train_levels; ++lev) {
        lev_corners = pattern_corners[lev];
        lev_descr = pattern_descriptors[lev];

        new_width = (lev0_img.cols*sc)|0;
        new_height = (lev0_img.rows*sc)|0;

        jsfeat.imgproc.resample(lev0_img, lev_img, new_width, new_height);
        jsfeat.imgproc.gaussian_blur(lev_img, lev_img, blur_size);
        corners_num = detect_keypoints(lev_img, lev_corners, max_per_level);
        jsfeat.orb.describe(lev_img, lev_corners, corners_num, lev_descr);

        // fix the coordinates due to scale level
        for(i = 0; i < corners_num; ++i) {
            lev_corners[i].x *= 1./sc;
            lev_corners[i].y *= 1./sc;
        }

        console.log("train " + lev_img.cols + "x" + lev_img.rows + " points: " + corners_num);

        sc /= sc_inc;
    }
    console.log(pattern_descriptors);
    console.log(pattern_corners);
	jsfeat.imgproc.grayscale(imageData2.data, image2.width, image2.height, scrShot_u8);
	jsfeat.imgproc.gaussian_blur(scrShot_u8, scrShot_u8_smooth, blur_size);
	num_scrShot_corners = detect_keypoints(scrShot_u8_smooth, scrShot_corners, 500);
    console.log("num corners2 : " + num_scrShot_corners);
	jsfeat.orb.describe(scrShot_u8_smooth, scrShot_corners, num_scrShot_corners, scrShot_descriptors);
    console.log(scrShot_descriptors);
	var num_matches = 0;
	var good_matches = 0;
	num_matches = match_pattern();
    console.log("Matches count : " + num_matches);
	good_matches = find_transform(matches, num_matches);
    console.log("Good matches count : " + good_matches);
    if(num_matches) {
        render_matches(ctx, matches, num_matches);
    }
	
  }
  </script>
</body>
</html>
